{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-03YUwbkrRK"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()\n"
      ],
      "metadata": {
        "id": "LWB3b3Jck0e9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv(\"/content/bitext-retail-banking-llm-chatbot-training-dataset.csv\")\n",
        "\n",
        "# İlk birkaç satırı inceleyelim\n",
        "df.head()\n"
      ],
      "metadata": {
        "id": "TB55k-K4k0hw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = df[['instruction', 'response']]"
      ],
      "metadata": {
        "id": "wh5R1we0k0k5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.dropna()"
      ],
      "metadata": {
        "id": "RJpL3AQ4k0nd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_dataset, eval_dataset = train_test_split(dataset, test_size=0.1)"
      ],
      "metadata": {
        "id": "xVB4qKrIk0qH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
        "\n",
        "model_name = \"t5-small\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "rQ5hLx4Ok0sL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_data(data, tokenizer, max_length=512):\n",
        "    inputs = [tokenizer.encode_plus(i, max_length=max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\") for i in data['instruction']]\n",
        "    labels = [tokenizer.encode(r, max_length=max_length, truncation=True, padding=\"max_length\", return_tensors=\"pt\") for r in data['response']]\n",
        "    return inputs, labels"
      ],
      "metadata": {
        "id": "OqcihWtwk0u_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "class BankingDataset(Dataset):\n",
        "    def __init__(self, data, tokenizer, max_length=512):\n",
        "        self.inputs, self.labels = encode_data(data, tokenizer, max_length)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.inputs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return {\n",
        "            'input_ids': self.inputs[idx]['input_ids'].squeeze(),\n",
        "            'attention_mask': self.inputs[idx]['attention_mask'].squeeze(),\n",
        "            'labels': self.labels[idx].squeeze()\n",
        "        }\n",
        "\n",
        "train_data = BankingDataset(train_dataset, tokenizer)\n",
        "eval_data = BankingDataset(eval_dataset, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_data, batch_size=8, shuffle=True)\n",
        "eval_loader = DataLoader(eval_data, batch_size=8)"
      ],
      "metadata": {
        "id": "izJp_U8xk0xN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_data,\n",
        "    eval_dataset=eval_data,\n",
        ")\n",
        "\n",
        "# Fine-tuning işlemini başlatın\n",
        "trainer.train()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HpowoyWak0zS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Modeli değerlendirin\n",
        "results = trainer.evaluate()\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "BuWArWE374JJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fine-tune edilmiş modeli kaydetme\n",
        "model.save_pretrained(\"./retail-banking-chatbot-model\")\n",
        "tokenizer.save_pretrained(\"./retail-banking-chatbot-model\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ltxwiibw8Ue2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}